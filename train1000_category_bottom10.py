import os
import json
import torchvision
import time
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import transforms, datasets
from tqdm import tqdm

from model import resnet34
rank = [1000, 369, 344, 225, 396, 741, 103, 513, 949, 147, 185, 571, 780, 867, 657, 526, 697, 772, 311, 331, 801, 202, 565, 547, 770, 140, 541, 222, 517, 403, 625, 525, 748, 840, 490, 88, 766, 95, 463, 757, 733, 351, 774, 300, 228, 530, 998, 564, 809, 399, 552, 286, 461, 924, 240, 394, 807, 864, 644, 566, 870, 950, 427, 928, 475, 73, 132, 34, 964, 887, 51, 381, 366, 316, 317, 28, 650, 930, 976, 479, 313, 320, 166, 847, 85, 746, 68, 875, 437, 660, 265, 941, 378, 467, 734, 431, 465, 196, 178, 797, 554, 727, 423, 961, 184, 159, 979, 447, 354, 829, 630, 277, 448, 80, 113, 965, 309, 687, 32, 821, 373, 903, 180, 81, 685, 197, 368, 921, 592, 91, 684, 134, 267, 631, 87, 20, 573, 881, 141, 664, 501, 607, 489, 915, 435, 765, 395, 57, 651, 6, 298, 643, 675, 429, 210, 715, 64, 558, 732, 694, 71, 207, 506, 590, 318, 738, 382, 798, 719, 290, 604, 596, 505, 305, 296, 690, 957, 866, 789, 112, 253, 686, 106, 128, 909, 288, 577, 913, 534, 156, 730, 487, 444, 60, 861, 42, 626, 400, 815, 472, 794, 58, 457, 835, 171, 910, 219, 811, 853, 613, 833, 802, 589, 509, 450, 209, 790, 583, 365, 15, 848, 327, 405, 786, 967, 548, 521, 533, 886, 659, 662, 198, 478, 484, 425, 191, 598, 215, 580, 720, 75, 83, 402, 586, 182, 947, 167, 667, 47, 93, 714, 994, 665, 434, 736, 97, 980, 248, 258, 374, 422, 107, 656, 837, 226, 211, 66, 620, 865, 269, 36, 982, 341, 914, 328, 763, 231, 988, 536, 999, 480, 174, 329, 175, 278, 518, 145, 289, 846, 481, 138, 46, 443, 647, 907, 754, 545, 235, 414, 432, 257, 469, 981, 22, 673, 129, 324, 12, 306, 591, 392, 610, 335, 232, 557, 163, 856, 814, 792, 805, 898, 535, 10, 951, 504, 161, 771, 652, 641, 372, 192, 560, 985, 350, 561, 672, 974, 340, 307, 878, 39, 410, 23, 773, 239, 725, 540, 393, 370, 713, 639, 63, 177, 84, 139, 810, 904, 25, 430, 243, 466, 711, 353, 109, 605, 627, 121, 918, 428, 99, 743, 874, 682, 549, 54, 795, 234, 850, 271, 279, 440, 364, 294, 751, 11, 332, 818, 176, 1, 776, 144, 38, 519, 116, 418, 333, 105, 978, 151, 945, 451, 255, 857, 384, 367, 588, 357, 154, 371, 168, 841, 537, 954, 397, 189, 796, 173, 876, 936, 880, 777, 708, 208, 143, 77, 623, 997, 745, 355, 323, 16, 758, 955, 862, 970, 808, 122, 587, 971, 252, 119, 762, 563, 539, 706, 820, 528, 275, 135, 65, 152, 622, 894, 984, 523, 756, 952, 778, 576, 446, 760, 500, 118, 649, 923, 485, 616, 959, 852, 508, 908, 680, 343, 254, 597, 768, 531, 137, 836, 705, 386, 524, 640, 775, 679, 502, 637, 670, 655, 285, 146, 419, 319, 205, 33, 230, 342, 102, 19, 187, 755, 338, 781, 783, 412, 556, 813, 498, 634, 376, 830, 688, 538, 170, 712, 912, 293, 624, 468, 575, 661, 889, 356, 869, 282, 609, 157, 438, 227, 345, 617, 348, 752, 716, 681, 242, 499, 30, 551, 213, 101, 804, 454, 858, 608, 718, 150, 740, 79, 731, 747, 761, 310, 742, 460, 570, 491, 653, 931, 89, 203, 800, 516, 45, 94, 989, 785, 822, 699, 104, 721, 825, 149, 911, 314, 407, 359, 532, 854, 724, 737, 220, 312, 702, 204, 550, 991, 767, 569, 408, 325, 495, 3, 352, 62, 787, 845, 944, 701, 948, 339, 581, 251, 110, 212, 510, 520, 969, 956, 621, 522, 710, 250, 404, 568, 417, 416, 453, 49, 241, 799, 839, 169, 148, 834, 476, 471, 668, 496, 124, 126, 722, 238, 299, 891, 494, 259, 906, 336, 677, 806, 926, 244, 831, 633, 206, 958, 669, 695, 779, 917, 599, 648, 263, 572, 155, 67, 181, 595, 127, 696, 629, 877, 379, 963, 233, 292, 274, 158, 901, 442, 983, 291, 973, 53, 223, 942, 214, 302, 663, 671, 542, 753, 347, 666, 507, 474, 358, 972, 188, 900, 7, 125, 791, 266, 937, 409, 55, 884, 477, 868, 2, 645, 268, 892, 458, 69, 593, 304, 391, 420, 388, 486, 849, 628, 938, 966, 421, 470, 692, 546, 142, 221, 115, 334, 165, 31, 939, 562, 642, 413, 21, 842, 493, 769, 635, 120, 674, 284, 916, 14, 873, 280, 824, 529, 827, 582, 578, 96, 788, 739, 8, 632, 133, 78, 111, 567, 377, 74, 70, 996, 488, 638, 415, 236, 82, 897, 424, 838, 703, 584, 37, 455, 646, 200, 114, 72, 482, 272, 683, 441, 123, 871, 380, 816, 308, 933, 361, 600, 303, 990, 195, 968, 689, 817, 844, 218, 445, 759, 18, 812, 246, 717, 832, 654, 728, 464, 579, 859, 885, 784, 946, 843, 29, 153, 462, 452, 676, 245, 962, 512, 98, 179, 433, 890, 992, 893, 297, 744, 960, 247, 935, 162, 17, 698, 749, 5, 44, 360, 52, 819, 261, 851, 117, 56, 943, 35, 337, 9, 497, 888, 401, 283, 515, 260, 895, 896, 237, 882, 224, 612, 398, 925, 987, 193, 108, 934, 879, 574, 41, 993, 86, 527, 4, 977, 603, 602, 59, 905, 863, 362, 553, 940, 160, 459, 349, 276, 90, 199, 514, 658, 503, 860, 449, 92, 61, 919, 782, 986, 723, 13, 363, 473, 735, 411, 826, 281, 385, 321, 436, 636, 929, 270, 823, 217, 190, 975, 301, 387, 229, 492, 707, 726, 614, 764, 709, 619, 618, 264, 330, 691, 26, 932, 43, 883, 27, 216, 750, 543, 326, 601, 40, 793, 606, 183, 899, 262, 136, 953, 678, 927, 611, 559, 172, 729, 872, 346, 920, 828, 390, 693, 256, 76, 483, 704, 375, 389, 555, 131, 426, 585, 594, 100, 50, 803, 273, 439, 315, 194, 456, 24, 511, 295, 700, 855, 164, 995, 130, 48, 383, 186, 615, 249, 544, 406, 922, 287, 201, 902, 322]
# category = [[0,1,2,8,9],[3,4,5,6,7]]
rank = [100, 21, 28, 72, 91, 51, 75, 82, 13, 84, 64, 30, 83, 80, 95, 68, 60, 8, 90, 67, 10, 32, 88, 26, 78, 59, 52, 58,
        99, 54, 96, 42, 2, 37, 27, 7, 69, 4, 53, 74, 39, 61, 70, 15, 66, 9, 43, 34, 33, 50, 3, 55, 31, 94, 36, 25, 62,
        47, 35, 45, 29, 63, 20, 87, 24, 81, 93, 18, 76, 22, 5, 97, 41, 49, 79, 71, 85, 1, 86, 89, 14, 56, 23, 46, 73,
        11, 12, 44, 17, 92, 19, 16, 57, 48, 6, 65, 98, 38, 40, 77]
top10 = [2, 21, 30, 31, 32, 33, 34, 41, 43, 45, 47, 60, 68, 69, 76, 97, 131, 135, 136, 146, 149, 195, 197, 199, 222, 223, 236, 243, 248, 250, 251, 278, 290, 295, 305, 308, 309, 316, 321, 372, 377, 378, 430, 432, 434, 457, 461, 510, 511, 514, 520, 527, 546, 575, 578, 591, 615, 630, 640, 647, 656, 660, 662, 664, 669, 670, 705, 706, 711, 716, 722, 726, 735, 742, 743, 754, 759, 770, 794, 801, 805, 807, 823, 824, 826, 834, 841, 863, 864, 868, 887, 908, 911, 917, 928, 933, 945, 972, 989, 992]

top20 = [2, 10, 16, 17, 21, 30, 31, 32, 33, 34, 35, 41, 43, 45, 47, 60, 68, 69, 70, 76, 82, 88, 97, 131, 132, 135, 136, 140, 146, 149, 156, 167, 178, 185, 192, 194, 195, 197, 199, 212, 218, 220, 222, 223, 225, 228, 231, 236, 243, 244, 246, 248, 250, 251, 256, 267, 272, 278, 280, 283, 290, 292, 295, 305, 308, 309, 310, 311, 312, 313, 315, 316, 321, 332, 351, 356, 358, 367, 372, 377, 378, 384, 404, 420, 430, 431, 432, 433, 434, 435, 451, 457, 460, 461, 470, 471, 474, 498, 503, 510, 511, 514, 520, 527, 543, 544, 546, 570, 573, 575, 578, 591, 593, 594, 599, 605, 615, 628, 629, 630, 631, 639, 640, 644, 647, 656, 660, 662, 664, 666, 667, 669, 670, 674, 700, 705, 706, 711, 715, 716, 719, 722, 726, 734, 735, 741, 742, 743, 748, 754, 756, 759, 767, 770, 787, 793, 794, 801, 805, 806, 807, 816, 821, 822, 823, 824, 826, 834, 835, 837, 841, 857, 859, 860, 863, 864, 865, 868, 881, 887, 898, 900, 903, 906, 908, 911, 915, 917, 920, 921, 928, 933, 945, 952, 971, 972, 982, 989, 992, 998]

top40 = [2, 10, 15, 16, 17, 21, 27, 28, 30, 31, 32, 33, 34, 35, 38, 40, 41, 42, 43, 45, 47, 51, 60, 61, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 80, 82, 88, 92, 97, 98, 100, 103, 104, 110, 115, 118, 119, 131, 132, 134, 135, 136, 137, 138, 140, 145, 146, 148, 149, 151, 152, 156, 158, 161, 162, 163, 167, 171, 172, 173, 174, 177, 178, 179, 183, 185, 190, 192, 194, 195, 197, 199, 200, 206, 208, 212, 214, 217, 218, 220, 222, 223, 224, 225, 226, 228, 231, 236, 240, 242, 243, 244, 246, 248, 250, 251, 253, 254, 255, 256, 261, 262, 264, 266, 267, 270, 272, 275, 278, 279, 280, 282, 283, 286, 290, 291, 292, 294, 295, 296, 297, 302, 305, 308, 309, 310, 311, 312, 313, 315, 316, 319, 321, 328, 332, 343, 344, 351, 356, 358, 366, 367, 368, 370, 372, 375, 377, 378, 379, 382, 384, 399, 402, 403, 404, 406, 407, 411, 418, 420, 421, 425, 428, 430, 431, 432, 433, 434, 435, 438, 439, 446, 447, 449, 451, 457, 458, 460, 461, 470, 471, 474, 475, 481, 498, 499, 503, 507, 509, 510, 511, 514, 520, 522, 523, 527, 529, 543, 544, 545, 546, 552, 554, 555, 557, 563, 564, 567, 569, 570, 573, 575, 576, 578, 580, 581, 583, 585, 591, 593, 594, 598, 599, 601, 602, 603, 605, 609, 611, 615, 616, 619, 623, 624, 628, 629, 630, 631, 634, 639, 640, 642, 643, 644, 647, 650, 653, 655, 656, 657, 658, 660, 662, 664, 666, 667, 668, 669, 670, 671, 674, 675, 684, 686, 687, 690, 694, 699, 700, 701, 702, 703, 705, 706, 707, 711, 713, 715, 716, 719, 722, 723, 726, 729, 734, 735, 738, 741, 742, 743, 744, 746, 747, 748, 751, 754, 756, 759, 760, 764, 765, 767, 770, 772, 775, 783, 787, 793, 794, 798, 801, 804, 805, 806, 807, 809, 810, 811, 816, 817, 821, 822, 823, 824, 826, 828, 834, 835, 837, 840, 841, 849, 852, 857, 859, 860, 862, 863, 864, 865, 868, 874, 880, 881, 885, 886, 887, 889, 891, 892, 894, 896, 897, 898, 900, 903, 906, 908, 911, 915, 917, 918, 920, 921, 924, 925, 928, 930, 933, 945, 950, 952, 954, 955, 962, 965, 971, 972, 973, 976, 980, 982, 983, 986, 989, 992, 996, 997, 998]

top80 = [2, 5, 7, 10, 14, 15, 16, 17, 21, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 50, 51, 53, 54, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 91, 92, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105, 109, 110, 112, 113, 115, 116, 118, 119, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 145, 146, 148, 149, 151, 152, 153, 155, 156, 158, 159, 160, 161, 162, 163, 165, 166, 167, 168, 169, 171, 172, 173, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184, 185, 186, 190, 192, 193, 194, 195, 196, 197, 199, 200, 202, 203, 204, 205, 206, 207, 208, 211, 212, 214, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 259, 260, 261, 262, 263, 264, 265, 266, 267, 269, 270, 272, 275, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 289, 290, 291, 292, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 323, 325, 326, 327, 328, 329, 330, 332, 333, 334, 335, 336, 337, 338, 342, 343, 344, 345, 346, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 366, 367, 368, 370, 371, 372, 373, 375, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 395, 399, 400, 401, 402, 403, 404, 405, 406, 407, 411, 412, 414, 415, 417, 418, 419, 420, 421, 422, 423, 424, 425, 427, 428, 429, 430, 431, 432, 433, 434, 435, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 449, 450, 451, 452, 455, 456, 457, 458, 460, 461, 462, 463, 464, 465, 466, 467, 468, 470, 471, 472, 473, 474, 475, 479, 481, 483, 485, 487, 489, 490, 491, 493, 494, 495, 496, 498, 499, 503, 504, 506, 507, 508, 509, 510, 511, 513, 514, 516, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 531, 532, 533, 534, 536, 537, 538, 539, 540, 543, 544, 545, 546, 547, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 563, 564, 565, 567, 568, 569, 570, 572, 573, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 587, 588, 591, 592, 593, 594, 596, 597, 598, 599, 601, 602, 603, 604, 605, 606, 607, 609, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 655, 656, 657, 658, 659, 660, 661, 662, 664, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 686, 687, 688, 689, 690, 694, 695, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 725, 726, 728, 729, 730, 731, 732, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 746, 747, 748, 749, 750, 751, 753, 754, 756, 757, 758, 759, 760, 761, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 781, 782, 783, 784, 785, 786, 787, 788, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 814, 815, 816, 817, 818, 821, 822, 823, 824, 825, 826, 827, 828, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 847, 849, 852, 855, 857, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 871, 872, 873, 874, 875, 876, 878, 879, 880, 881, 885, 886, 887, 888, 889, 890, 891, 892, 894, 896, 897, 898, 899, 900, 903, 904, 906, 907, 908, 909, 910, 911, 913, 914, 915, 917, 918, 920, 921, 922, 923, 924, 925, 926, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 940, 942, 943, 944, 945, 946, 947, 948, 949, 950, 952, 953, 954, 955, 956, 958, 959, 961, 962, 963, 965, 966, 968, 969, 970, 971, 972, 973, 976, 977, 978, 980, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 995, 996, 997, 998]


def main():
    # for i in [10,20,30,40,50,60,70,80,90]:
    top10.sort()
    top20.sort()
    top40.sort()
    top80.sort()
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    print("using {} device.".format(device))
    # print(i)
    data_transform = {
        "train": transforms.Compose([transforms.Resize(256),
                                     transforms.CenterCrop(224),
                                     transforms.ToTensor(),
                                     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),
        "val": transforms.Compose([transforms.Resize(256),
                                   transforms.CenterCrop(224),
                                   transforms.ToTensor(),
                                   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])}

    train_set = torchvision.datasets.CIFAR10(root='datasets', train=True,
                                             download=False, transform=data_transform["train"])
    # 加载训练集，实际过程需要分批次（batch）训练
    train_loader = torch.utils.data.DataLoader(train_set, batch_size=1000,
                                               shuffle=False, num_workers=0)

    # 10000张测试图片
    test_set = torchvision.datasets.CIFAR10(root='datasets', train=False,
                                            download=False, transform=data_transform["val"])
    val_num = len(test_set)
    test_loader = torch.utils.data.DataLoader(test_set, batch_size=10,
                                              shuffle=False, num_workers=0)

    # test_loader2 = torch.utils.data.DataLoader(test_set, batch_size=100,
    #                                           shuffle=False, num_workers=0)
    # test_data_iter2 = iter(test_loader2)
    # test_image2, test_label2 = test_data_iter2.next()
    # test_label333 = test_label2.clone()
    # test_label333[0] = 10

    net = resnet34()

    # change fc layer structure
    in_channel = net.fc.in_features
    net.fc = nn.Linear(in_channel, 10)
    net.to(device)


    # load pretrain weights
    # download url: https://download.pytorch.org/models/resnet34-333f7ec4.pth
    # model_weight_path = "./pth_file4_1000/resNet34_epoch1_1000.pth"
    model_weight_path = './pth_file7_1000_nopre/resNet34_epoch2_1000_2.pth'
    # model_weight_path = "pth_file1/resnet34-pre.pth"
    assert os.path.exists(model_weight_path), "file {} does not exist.".format(model_weight_path)
    net.load_state_dict(torch.load(model_weight_path, map_location=device))

    # for param in net.parameters():
    #     param.requires_grad = False




    train_data_iter = iter(train_loader)
    train_image, train_label = train_data_iter.next()
    train_extract = torch.zeros(1000, 3, 224, 224)
    label_extract = torch.zeros(1000).long()
    for i in range(1000):
        train_extract[i] = train_image[i]
        label_extract[i] = train_label[i]

    train_top10 = torch.zeros(len(top10), 3, 224, 224)
    label_top10 = torch.zeros(len(top10)).long()
    for i in range(len(top10)):
        train_top10[i] = train_image[top10[i]]
        label_top10[i] = train_label[top10[i]]

    train_top20 = torch.zeros(len(top20), 3, 224, 224)
    label_top20 = torch.zeros(len(top20)).long()
    for i in range(len(top20)):
        train_top20[i] = train_image[top20[i]]
        label_top20[i] = train_label[top20[i]]

    train_top40 = torch.zeros(len(top40), 3, 224, 224)
    label_top40 = torch.zeros(len(top40)).long()
    for i in range(len(top40)):
        train_top40[i] = train_image[top40[i]]
        label_top40[i] = train_label[top40[i]]

    train_top80 = torch.zeros(len(top80), 3, 224, 224)
    label_top80 = torch.zeros(len(top80)).long()
    for i in range(len(top80)):
        train_top80[i] = train_image[top80[i]]
        label_top80[i] = train_label[top80[i]]



    # define loss function
    loss_function = nn.CrossEntropyLoss()

    # construct an optimizer
    params = [p for p in net.parameters() if p.requires_grad]
    optimizer = optim.Adam(params, lr=0.0001)

    epochs = 30
    best_acc = 0.0
    save_path = './pth_file4_1000/resNet34_tracin_epoch{}_{}.pth'  # save_path = './resNet34_new.pth'
    save_path = './pth_file7_1000_nopre/resNet34_epoch{}_1000_2.pth'
    train_steps = len(train_loader)
    for epoch in range(epochs):
        # train
        net.train()
        time_start = time.perf_counter()
        running_loss = 0.0
        # train_bar = tqdm(train_loader)
        # for step, data in enumerate(train_bar):
        for step in range(100):
            if (step < 10):
                # images, labels = data

                optimizer.zero_grad()

                logits = net(train_extract[100+step*10:100+step*10+9].to(device))
                loss = loss_function(logits, label_extract[100+step*10:100+step*10+9].to(device))
                loss.backward()
                optimizer.step()
            #     if(step == 99):
            #         torch.save(net.state_dict(), save_path)
            # #
            # #     # print statistics
                running_loss += loss.item()
            # else:
            #     if (step < 10):
            #         optimizer.zero_grad()
            #         logits = net(train_extract[step * 10:step * 10 + 9].to(device))
            #         loss = loss_function(logits, label_extract[step * 10:step * 10 + 9].to(device))
            #         loss.backward()
            #         optimizer.step()
            #
            # if (step == 99 and epoch == 0):
            #     # torch.save(net.state_dict(), save_path + str(step) + '.pth')
            #     torch.save(net.state_dict(), save_path)
            # if (epoch == 0):
            #     if (step < 100 and rank[step] > i):
            #         images, labels = data
            #
            #         optimizer.zero_grad()
            #         logits = net(images.to(device))
            #         loss = loss_function(logits, labels.to(device))
            #         loss.backward()
            #         optimizer.step()
            #
            #         # print statistics
            #         running_loss += loss.item()
            # elif(epoch == 1):
            #     if (step < 100 and rank[step] > (100 - i)):
            #         images, labels = data
            #
            #         optimizer.zero_grad()
            #         logits = net(images.to(device))
            #         loss = loss_function(logits, labels.to(device))
            #         loss.backward()
            #         optimizer.step()

                    # print statistics
                    # running_loss += loss.item()

        net.eval()
        acc = 0.0
        with torch.no_grad():
            val_bar = tqdm(test_loader)
            for val_data in val_bar:
                val_images, val_labels = val_data
                outputs = net(val_images.to(device))
                # loss = loss_function(outputs, test_labels)
                predict_y = torch.max(outputs, dim=1)[1]
                acc += torch.eq(predict_y, val_labels.to(device)).sum().item()

            val_accurate = acc / 10000
            print('[%d, %5d] train_loss: %.3f  test_accuracy: %.3f' %  # 打印epoch，step，loss，accuracy
                  (epoch + 1, step + 1, running_loss / 10, val_accurate))

            print('%f s' % (time.perf_counter() - time_start))  # 打印耗时
            # train_bar.desc = "train epoch[{}/{}] loss:{:.3f}".format(epoch + 1,
            #                                                          epochs,
            #                                                          loss)

        # if val_accurate > best_acc:
        #     best_acc = val_accurate
        #     torch.save(net.state_dict(), save_path.format(epoch+1))

    print('Finished Training')


if __name__ == '__main__':
    main()
