import os
import json
import torchvision
import time
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import transforms, datasets
from tqdm import tqdm

from model import resnet34
rank = [1000, 369, 344, 225, 396, 741, 103, 513, 949, 147, 185, 571, 780, 867, 657, 526, 697, 772, 311, 331, 801, 202, 565, 547, 770, 140, 541, 222, 517, 403, 625, 525, 748, 840, 490, 88, 766, 95, 463, 757, 733, 351, 774, 300, 228, 530, 998, 564, 809, 399, 552, 286, 461, 924, 240, 394, 807, 864, 644, 566, 870, 950, 427, 928, 475, 73, 132, 34, 964, 887, 51, 381, 366, 316, 317, 28, 650, 930, 976, 479, 313, 320, 166, 847, 85, 746, 68, 875, 437, 660, 265, 941, 378, 467, 734, 431, 465, 196, 178, 797, 554, 727, 423, 961, 184, 159, 979, 447, 354, 829, 630, 277, 448, 80, 113, 965, 309, 687, 32, 821, 373, 903, 180, 81, 685, 197, 368, 921, 592, 91, 684, 134, 267, 631, 87, 20, 573, 881, 141, 664, 501, 607, 489, 915, 435, 765, 395, 57, 651, 6, 298, 643, 675, 429, 210, 715, 64, 558, 732, 694, 71, 207, 506, 590, 318, 738, 382, 798, 719, 290, 604, 596, 505, 305, 296, 690, 957, 866, 789, 112, 253, 686, 106, 128, 909, 288, 577, 913, 534, 156, 730, 487, 444, 60, 861, 42, 626, 400, 815, 472, 794, 58, 457, 835, 171, 910, 219, 811, 853, 613, 833, 802, 589, 509, 450, 209, 790, 583, 365, 15, 848, 327, 405, 786, 967, 548, 521, 533, 886, 659, 662, 198, 478, 484, 425, 191, 598, 215, 580, 720, 75, 83, 402, 586, 182, 947, 167, 667, 47, 93, 714, 994, 665, 434, 736, 97, 980, 248, 258, 374, 422, 107, 656, 837, 226, 211, 66, 620, 865, 269, 36, 982, 341, 914, 328, 763, 231, 988, 536, 999, 480, 174, 329, 175, 278, 518, 145, 289, 846, 481, 138, 46, 443, 647, 907, 754, 545, 235, 414, 432, 257, 469, 981, 22, 673, 129, 324, 12, 306, 591, 392, 610, 335, 232, 557, 163, 856, 814, 792, 805, 898, 535, 10, 951, 504, 161, 771, 652, 641, 372, 192, 560, 985, 350, 561, 672, 974, 340, 307, 878, 39, 410, 23, 773, 239, 725, 540, 393, 370, 713, 639, 63, 177, 84, 139, 810, 904, 25, 430, 243, 466, 711, 353, 109, 605, 627, 121, 918, 428, 99, 743, 874, 682, 549, 54, 795, 234, 850, 271, 279, 440, 364, 294, 751, 11, 332, 818, 176, 1, 776, 144, 38, 519, 116, 418, 333, 105, 978, 151, 945, 451, 255, 857, 384, 367, 588, 357, 154, 371, 168, 841, 537, 954, 397, 189, 796, 173, 876, 936, 880, 777, 708, 208, 143, 77, 623, 997, 745, 355, 323, 16, 758, 955, 862, 970, 808, 122, 587, 971, 252, 119, 762, 563, 539, 706, 820, 528, 275, 135, 65, 152, 622, 894, 984, 523, 756, 952, 778, 576, 446, 760, 500, 118, 649, 923, 485, 616, 959, 852, 508, 908, 680, 343, 254, 597, 768, 531, 137, 836, 705, 386, 524, 640, 775, 679, 502, 637, 670, 655, 285, 146, 419, 319, 205, 33, 230, 342, 102, 19, 187, 755, 338, 781, 783, 412, 556, 813, 498, 634, 376, 830, 688, 538, 170, 712, 912, 293, 624, 468, 575, 661, 889, 356, 869, 282, 609, 157, 438, 227, 345, 617, 348, 752, 716, 681, 242, 499, 30, 551, 213, 101, 804, 454, 858, 608, 718, 150, 740, 79, 731, 747, 761, 310, 742, 460, 570, 491, 653, 931, 89, 203, 800, 516, 45, 94, 989, 785, 822, 699, 104, 721, 825, 149, 911, 314, 407, 359, 532, 854, 724, 737, 220, 312, 702, 204, 550, 991, 767, 569, 408, 325, 495, 3, 352, 62, 787, 845, 944, 701, 948, 339, 581, 251, 110, 212, 510, 520, 969, 956, 621, 522, 710, 250, 404, 568, 417, 416, 453, 49, 241, 799, 839, 169, 148, 834, 476, 471, 668, 496, 124, 126, 722, 238, 299, 891, 494, 259, 906, 336, 677, 806, 926, 244, 831, 633, 206, 958, 669, 695, 779, 917, 599, 648, 263, 572, 155, 67, 181, 595, 127, 696, 629, 877, 379, 963, 233, 292, 274, 158, 901, 442, 983, 291, 973, 53, 223, 942, 214, 302, 663, 671, 542, 753, 347, 666, 507, 474, 358, 972, 188, 900, 7, 125, 791, 266, 937, 409, 55, 884, 477, 868, 2, 645, 268, 892, 458, 69, 593, 304, 391, 420, 388, 486, 849, 628, 938, 966, 421, 470, 692, 546, 142, 221, 115, 334, 165, 31, 939, 562, 642, 413, 21, 842, 493, 769, 635, 120, 674, 284, 916, 14, 873, 280, 824, 529, 827, 582, 578, 96, 788, 739, 8, 632, 133, 78, 111, 567, 377, 74, 70, 996, 488, 638, 415, 236, 82, 897, 424, 838, 703, 584, 37, 455, 646, 200, 114, 72, 482, 272, 683, 441, 123, 871, 380, 816, 308, 933, 361, 600, 303, 990, 195, 968, 689, 817, 844, 218, 445, 759, 18, 812, 246, 717, 832, 654, 728, 464, 579, 859, 885, 784, 946, 843, 29, 153, 462, 452, 676, 245, 962, 512, 98, 179, 433, 890, 992, 893, 297, 744, 960, 247, 935, 162, 17, 698, 749, 5, 44, 360, 52, 819, 261, 851, 117, 56, 943, 35, 337, 9, 497, 888, 401, 283, 515, 260, 895, 896, 237, 882, 224, 612, 398, 925, 987, 193, 108, 934, 879, 574, 41, 993, 86, 527, 4, 977, 603, 602, 59, 905, 863, 362, 553, 940, 160, 459, 349, 276, 90, 199, 514, 658, 503, 860, 449, 92, 61, 919, 782, 986, 723, 13, 363, 473, 735, 411, 826, 281, 385, 321, 436, 636, 929, 270, 823, 217, 190, 975, 301, 387, 229, 492, 707, 726, 614, 764, 709, 619, 618, 264, 330, 691, 26, 932, 43, 883, 27, 216, 750, 543, 326, 601, 40, 793, 606, 183, 899, 262, 136, 953, 678, 927, 611, 559, 172, 729, 872, 346, 920, 828, 390, 693, 256, 76, 483, 704, 375, 389, 555, 131, 426, 585, 594, 100, 50, 803, 273, 439, 315, 194, 456, 24, 511, 295, 700, 855, 164, 995, 130, 48, 383, 186, 615, 249, 544, 406, 922, 287, 201, 902, 322]
# category = [[0,1,2,8,9],[3,4,5,6,7]]
rank = [100, 21, 28, 72, 91, 51, 75, 82, 13, 84, 64, 30, 83, 80, 95, 68, 60, 8, 90, 67, 10, 32, 88, 26, 78, 59, 52, 58,
        99, 54, 96, 42, 2, 37, 27, 7, 69, 4, 53, 74, 39, 61, 70, 15, 66, 9, 43, 34, 33, 50, 3, 55, 31, 94, 36, 25, 62,
        47, 35, 45, 29, 63, 20, 87, 24, 81, 93, 18, 76, 22, 5, 97, 41, 49, 79, 71, 85, 1, 86, 89, 14, 56, 23, 46, 73,
        11, 12, 44, 17, 92, 19, 16, 57, 48, 6, 65, 98, 38, 40, 77]

top10 = [3, 52, 154, 180, 189, 258, 276, 416, 477, 883,6, 9, 37, 114, 201, 369, 830, 895, 941, 968,25, 396, 409, 436, 548, 691,
 697, 755, 846, 877,0, 63, 106, 273, 397, 426, 515, 586, 829, 916,22, 26, 58, 117, 188, 324, 365, 500, 505, 595,12, 24,
 238, 478, 484, 488, 502, 518, 525, 937,4, 19, 49, 413, 501, 574, 685, 901, 902, 994,13, 57, 99, 410, 621, 693, 808, 850,
 858, 905,1, 55, 108, 164, 191, 274, 482, 492, 665, 999,11, 89, 293, 394, 530, 566, 589, 625, 752, 884]
top80 = [3, 27, 44, 52, 74, 90, 98, 111, 116, 125, 153, 154, 169, 179, 180, 189, 206, 215, 235, 237, 255, 257, 258, 269, 276, 281, 284, 287, 297, 298, 338, 352, 359, 376, 382, 398, 406, 416, 422, 423, 428, 447, 473, 477, 489, 491, 496, 499, 522, 524, 526, 531, 539, 560, 581, 584, 602, 638, 675, 678, 689, 763, 774, 778, 785, 791, 814, 847, 854, 883, 886, 888, 912, 914, 919, 929, 944, 946, 956, 975,6, 9, 37, 66, 81, 82, 104, 105, 114, 122, 134, 161, 193, 201, 204, 231, 240, 241, 246, 261, 283, 286, 325, 330, 351, 363, 366, 369, 390, 407, 414, 439, 440, 462, 490, 493, 494, 513, 540, 572, 594, 604, 619, 622, 629, 645, 657, 659, 668, 677, 723, 736, 738, 753, 764, 771, 781, 796, 801, 830, 836, 844, 865, 869, 871, 894, 895, 906, 915, 941, 947, 953, 961, 962, 968, 973, 978, 987, 990, 997,25, 65, 67, 75, 84, 86, 113, 118, 123, 129, 138, 147, 160, 182, 183, 219, 249, 266, 270, 291, 303, 307, 322, 340, 342, 353, 354, 357, 374, 387, 388, 391, 393, 396, 409, 424, 436, 448, 449, 450, 497, 537, 548, 559, 563, 564, 569, 592, 603, 618, 623, 655, 691, 692, 697, 701, 725, 731, 740, 751, 755, 758, 765, 775, 776, 799, 813, 832, 833, 839, 843, 846, 848, 873, 877, 931, 935, 936, 980, 988,0, 8, 46, 53, 61, 63, 77, 78, 91, 103, 106, 115, 121, 127, 143, 176, 184, 187, 205, 224, 245, 271, 273, 277, 279, 294, 320, 323, 336, 397, 412, 418, 426, 438, 453, 456, 464, 467, 515, 558, 565, 586, 597, 607, 608, 637, 641, 646, 671, 673, 676, 688, 690, 695, 727, 739, 760, 786, 790, 792, 811, 819, 825, 829, 831, 845, 862, 866, 870, 874, 878, 882, 896, 916, 932, 948, 950, 957, 986, 995,22, 26, 36, 40, 58, 94, 100, 110, 117, 130, 159, 165, 167, 188, 211, 227, 254, 267, 314, 324, 328, 346, 365, 370, 373, 405, 420, 427, 441, 455, 458, 463, 465, 466, 479, 500, 503, 505, 509, 528, 555, 557, 580, 583, 587, 595, 606, 627, 628, 648, 658, 661, 682, 702, 714, 718, 720, 730, 737, 769, 773, 793, 797, 802, 804, 835, 849, 860, 872, 876, 881, 889, 890, 913, 930, 943, 954, 971, 983, 993,12, 16, 24, 33, 39, 42, 85, 101, 128, 141, 148, 155, 158, 168, 178, 181, 190, 200, 207, 212, 230, 232, 238, 239, 250, 262, 275, 318, 319, 321, 327, 343, 345, 361, 389, 421, 431, 437, 444, 446, 460, 474, 478, 483, 484, 488, 502, 518, 525, 533, 544, 549, 550, 551, 553, 579, 598, 601, 614, 631, 639, 640, 649, 652, 679, 699, 729, 749, 768, 779, 810, 817, 828, 899, 903, 910, 924, 925, 937, 991,4, 5, 7, 19, 29, 49, 59, 62, 64, 71, 93, 95, 96, 102, 107, 112, 142, 152, 162, 186, 221, 226, 229, 296, 299, 300, 301, 304, 329, 333, 334, 341, 347, 380, 392, 395, 413, 429, 459, 476, 501, 512, 534, 535, 536, 542, 547, 556, 562, 574, 590, 610, 617, 632, 635, 663, 672, 681, 685, 710, 728, 747, 761, 762, 777, 783, 788, 820, 827, 861, 893, 901, 902, 907, 927, 963, 964, 966, 976, 994,13, 20, 48, 56, 57, 83, 87, 99, 109, 119, 137, 177, 198, 203, 208, 210, 216, 263, 268, 288, 317, 326, 339, 355, 371, 375, 386, 402, 410, 417, 419, 445, 452, 468, 475, 506, 521, 523, 541, 561, 567, 571, 596, 620, 621, 624, 634, 643, 693, 698, 704, 713, 732, 745, 766, 782, 784, 795, 798, 800, 803, 808, 809, 812, 840, 842, 850, 855, 856, 858, 867, 879, 892, 897, 905, 934, 942, 958, 974, 984,1, 15, 18, 54, 55, 79, 108, 120, 124, 126, 144, 150, 164, 166, 173, 191, 196, 202, 214, 233, 234, 242, 260, 265, 274, 306, 337, 344, 348, 362, 385, 401, 403, 408, 469, 472, 480, 482, 492, 495, 516, 519, 552, 576, 582, 588, 600, 612, 613, 633, 636, 665, 683, 694, 696, 703, 708, 709, 712, 717, 721, 724, 757, 789, 815, 818, 852, 875, 880, 904, 909, 918, 926, 939, 949, 959, 977, 985, 996, 999,11, 14, 23, 50, 89, 133, 139, 157, 170, 172, 174, 175, 209, 213, 247, 252, 259, 285, 289, 293, 331, 335, 349, 350, 360, 364, 381, 383, 394, 400, 411, 415, 425, 442, 443, 454, 485, 486, 487, 504, 507, 508, 517, 530, 532, 538, 545, 554, 566, 568, 577, 585, 589, 609, 625, 626, 651, 654, 680, 686, 733, 744, 750, 752, 780, 838, 851, 853, 884, 922, 923, 938, 940, 951, 960, 967, 969, 970, 979, 981]

top40 = [3, 44, 52, 90, 111, 125, 154, 180, 189, 215, 257, 258, 269, 276, 281, 284, 287, 298, 352, 376, 398, 416, 423, 477, 489, 496, 531, 539, 584, 638, 763, 785, 814, 854, 883, 912, 919, 929, 944, 975,3, 44, 52, 90, 111, 125, 154, 180, 189, 215, 257, 258, 269, 276, 281, 284, 287, 298, 352, 376, 398, 416, 423, 477, 489, 496, 531, 539, 584, 638, 763, 785, 814, 854, 883, 912, 919, 929, 944, 975,25, 84, 113, 147, 182, 219, 307, 322, 340, 357, 374, 391, 393, 396, 409, 424, 436, 448, 450, 497, 548, 691, 692, 697, 725, 731, 740, 755, 776, 799, 813, 832, 833, 839, 846, 848, 873, 877, 935, 936,0, 8, 63, 77, 106, 121, 127, 143, 176, 184, 187, 245, 271, 273, 323, 397, 426, 453, 464, 515, 558, 565, 586, 607, 608, 637, 688, 727, 790, 819, 829, 831, 845, 866, 870, 878, 882, 916, 948, 957,22, 26, 36, 58, 117, 159, 188, 211, 227, 314, 324, 346, 365, 373, 405, 427, 441, 455, 466, 479, 500, 505, 528, 587, 595, 606, 648, 661, 714, 718, 720, 730, 769, 773, 797, 802, 872, 876, 943, 993,12, 24, 39, 85, 101, 128, 141, 155, 168, 181, 207, 230, 232, 238, 239, 327, 345, 361, 437, 444, 478, 483, 484, 488, 502, 518, 525, 533, 549, 551, 553, 579, 614, 679, 768, 779, 899, 910, 937, 991,4, 5, 7, 19, 49, 59, 93, 107, 142, 221, 229, 333, 341, 347, 380, 392, 413, 459, 476, 501, 512, 535, 542, 562, 574, 590, 610, 635, 663, 685, 762, 777, 820, 827, 893, 901, 902, 927, 964, 994,13, 20, 56, 57, 87, 99, 198, 210, 216, 263, 268, 288, 326, 339, 355, 371, 410, 417, 452, 468, 541, 561, 571, 620, 621, 693, 732, 745, 766, 808, 812, 842, 850, 856, 858, 867, 905, 934, 974, 984,1, 18, 55, 79, 108, 120, 124, 144, 150, 164, 166, 191, 196, 234, 274, 306, 337, 348, 362, 385, 408, 469, 472, 480, 482, 492, 582, 588, 600, 636, 665, 696, 708, 721, 724, 789, 939, 949, 977, 999,11, 14, 23, 50, 89, 157, 170, 209, 213, 247, 252, 259, 293, 331, 383, 394, 443, 454, 486, 508, 517, 530, 566, 577, 589, 625, 654, 733, 752, 780, 851, 853, 884, 922, 951, 960, 967, 970, 979, 981]

top20 = [3, 44, 52, 90, 111, 154, 180, 189, 215, 257, 258, 276, 287, 376, 416, 477, 638, 854, 883, 919,6, 9, 37, 114, 193, 201, 325, 369, 494, 677, 781, 830, 836, 871, 895, 941, 947, 968, 987, 990,25, 147, 322, 340, 374, 393, 396, 409, 436, 448, 497, 548, 691, 692, 697, 755, 813, 846, 848, 877,0, 63, 77, 106, 187, 271, 273, 397, 426, 453, 515, 586, 608, 727, 829, 845, 870, 882, 916, 957,22, 26, 58, 117, 159, 188, 211, 324, 365, 405, 500, 505, 587, 595, 606, 648, 718, 720, 773, 802,12, 24, 128, 155, 232, 238, 327, 345, 444, 478, 484, 488, 502, 518, 525, 533, 679, 779, 899, 937,4, 19, 49, 59, 142, 229, 347, 413, 459, 501, 542, 562, 574, 663, 685, 901, 902, 927, 964, 994,13, 20, 56, 57, 99, 198, 268, 339, 410, 561, 571, 621, 693, 745, 808, 850, 856, 858, 905, 974,1, 18, 55, 108, 120, 150, 164, 191, 274, 348, 480, 482, 492, 600, 665, 696, 724, 789, 939, 999,11, 89, 170, 209, 213, 293, 394, 454, 530, 566, 589, 625, 654, 752, 853, 884, 951, 960, 979, 981]


def main():
    # for i in [10,20,30,40,50,60,70,80,90]:
    top10.sort()
    top20.sort()
    top40.sort()
    top80.sort()
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    print("using {} device.".format(device))
    # print(i)
    data_transform = {
        "train": transforms.Compose([transforms.Resize(256),
                                     transforms.CenterCrop(224),
                                     transforms.ToTensor(),
                                     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),
        "val": transforms.Compose([transforms.Resize(256),
                                   transforms.CenterCrop(224),
                                   transforms.ToTensor(),
                                   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])}

    train_set = torchvision.datasets.CIFAR10(root='datasets', train=True,
                                             download=False, transform=data_transform["train"])
    # 加载训练集，实际过程需要分批次（batch）训练
    train_loader = torch.utils.data.DataLoader(train_set, batch_size=1000,
                                               shuffle=False, num_workers=0)

    # 10000张测试图片
    test_set = torchvision.datasets.CIFAR10(root='datasets', train=False,
                                            download=False, transform=data_transform["val"])
    val_num = len(test_set)
    test_loader = torch.utils.data.DataLoader(test_set, batch_size=10,
                                              shuffle=False, num_workers=0)

    # test_loader2 = torch.utils.data.DataLoader(test_set, batch_size=100,
    #                                           shuffle=False, num_workers=0)
    # test_data_iter2 = iter(test_loader2)
    # test_image2, test_label2 = test_data_iter2.next()
    # test_label333 = test_label2.clone()
    # test_label333[0] = 10

    net = resnet34()

    # change fc layer structure
    in_channel = net.fc.in_features
    net.fc = nn.Linear(in_channel, 10)
    net.to(device)


    # load pretrain weights
    # download url: https://download.pytorch.org/models/resnet34-333f7ec4.pth
    # model_weight_path = "./pth_file4_1000/resNet34_epoch1_1000.pth"
    model_weight_path = './pth_file7_1000_nopre/resNet34_epoch2_1000_2.pth'
    # model_weight_path = "pth_file1/resnet34-pre.pth"
    assert os.path.exists(model_weight_path), "file {} does not exist.".format(model_weight_path)
    net.load_state_dict(torch.load(model_weight_path, map_location=device))

    # for param in net.parameters():
    #     param.requires_grad = False




    train_data_iter = iter(train_loader)
    train_image, train_label = train_data_iter.next()
    train_extract = torch.zeros(1000, 3, 224, 224)
    label_extract = torch.zeros(1000).long()
    for i in range(1000):
        train_extract[i] = train_image[i]
        label_extract[i] = train_label[i]

    train_top10 = torch.zeros(len(top10), 3, 224, 224)
    label_top10 = torch.zeros(len(top10)).long()
    for i in range(len(top10)):
        train_top10[i] = train_image[top10[i]]
        label_top10[i] = train_label[top10[i]]

    train_top20 = torch.zeros(len(top20), 3, 224, 224)
    label_top20 = torch.zeros(len(top20)).long()
    for i in range(len(top20)):
        train_top20[i] = train_image[top20[i]]
        label_top20[i] = train_label[top20[i]]

    train_top40 = torch.zeros(len(top40), 3, 224, 224)
    label_top40 = torch.zeros(len(top40)).long()
    for i in range(len(top40)):
        train_top40[i] = train_image[top40[i]]
        label_top40[i] = train_label[top40[i]]

    train_top80 = torch.zeros(len(top80), 3, 224, 224)
    label_top80 = torch.zeros(len(top80)).long()
    for i in range(len(top80)):
        train_top80[i] = train_image[top80[i]]
        label_top80[i] = train_label[top80[i]]



    # define loss function
    loss_function = nn.CrossEntropyLoss()

    # construct an optimizer
    params = [p for p in net.parameters() if p.requires_grad]
    optimizer = optim.Adam(params, lr=0.0001)

    epochs = 45
    best_acc = 0.0
    save_path = './pth_file4_1000/resNet34_tracin_epoch{}_{}.pth'  # save_path = './resNet34_new.pth'
    save_path = './pth_file7_1000_nopre/resNet34_epoch{}_1000_2.pth'
    train_steps = len(train_loader)
    for epoch in range(epochs):
        # train
        net.train()
        time_start = time.perf_counter()
        running_loss = 0.0
        # train_bar = tqdm(train_loader)
        # for step, data in enumerate(train_bar):
        for step in range(100):
            if (step < 80):
                # images, labels = data

                optimizer.zero_grad()
                logits = net(train_top80[step*10:step*10+9].to(device))
                loss = loss_function(logits, label_top80[step*10:step*10+9].to(device))
                loss.backward()
                optimizer.step()
            #     if(step == 99):
            #         torch.save(net.state_dict(), save_path)
            # #
            # #     # print statistics
                running_loss += loss.item()
            # else:
            #     if (step < 10):
            #         optimizer.zero_grad()
            #         logits = net(train_extract[step * 10:step * 10 + 9].to(device))
            #         loss = loss_function(logits, label_extract[step * 10:step * 10 + 9].to(device))
            #         loss.backward()
            #         optimizer.step()
            #
            # if (step == 99 and epoch == 0):
            #     # torch.save(net.state_dict(), save_path + str(step) + '.pth')
            #     torch.save(net.state_dict(), save_path)
            # if (epoch == 0):
            #     if (step < 100 and rank[step] > i):
            #         images, labels = data
            #
            #         optimizer.zero_grad()
            #         logits = net(images.to(device))
            #         loss = loss_function(logits, labels.to(device))
            #         loss.backward()
            #         optimizer.step()
            #
            #         # print statistics
            #         running_loss += loss.item()
            # elif(epoch == 1):
            #     if (step < 100 and rank[step] > (100 - i)):
            #         images, labels = data
            #
            #         optimizer.zero_grad()
            #         logits = net(images.to(device))
            #         loss = loss_function(logits, labels.to(device))
            #         loss.backward()
            #         optimizer.step()

                    # print statistics
                    # running_loss += loss.item()

        net.eval()
        acc = 0.0
        with torch.no_grad():
            val_bar = tqdm(test_loader)
            for val_data in val_bar:
                val_images, val_labels = val_data
                outputs = net(val_images.to(device))
                # loss = loss_function(outputs, test_labels)
                predict_y = torch.max(outputs, dim=1)[1]
                acc += torch.eq(predict_y, val_labels.to(device)).sum().item()

            val_accurate = acc / 10000
            print('[%d, %5d] train_loss: %.3f  test_accuracy: %.3f' %  # 打印epoch，step，loss，accuracy
                  (epoch + 1, step + 1, running_loss / 10, val_accurate))

            print('%f s' % (time.perf_counter() - time_start))  # 打印耗时
            # train_bar.desc = "train epoch[{}/{}] loss:{:.3f}".format(epoch + 1,
            #                                                          epochs,
            #                                                          loss)

        # if val_accurate > best_acc:
        #     best_acc = val_accurate
        #     torch.save(net.state_dict(), save_path.format(epoch+1))

    print('Finished Training')


if __name__ == '__main__':
    main()
